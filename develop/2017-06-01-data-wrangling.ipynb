{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "Explore the experimental data & convert to HDDM-ready format (CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune output for individual .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "\n",
    "# Import .mat file as python object\n",
    "data = scio.loadmat('../data/data_18333.mat', struct_as_record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's focus on the following:  \n",
    "- Reaction time (rt)  \n",
    "- Response (0/1)  \n",
    "- Stimulus (1-4 for now)  \n",
    "\n",
    "This is similar to `examples/hddm_simple.csv`, used to play around with the HDDM library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_struct = data['data'][0,0]  # Actual data structure, owns to matlab weirdness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before outputing to CSV, data for each subject will go in a python dictionary in the form of key --> array. The plan is to then create an array of dictionaries for all patients, with each dictionary representing the data gathered for an individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conversion from convoluted numpy array that scipy.io spits out to a more\n",
    "pythonic data structure.\n",
    "Leverage python instead of numpy for data manipulation, since the use of\n",
    "numpy isn't really necessary for this data.\n",
    "\"\"\"\n",
    "\n",
    "#subject['rt'] = dat_struct.rt1.tolist()[0]\n",
    "#subject['response'] = [x[0] for x in dat_struct.perf1.tolist()]\n",
    "#subject['stim'] = [x[0] for x in dat_struct.conditions1.tolist()]\n",
    "\n",
    "csv_keys = ['rt', 'response', 'stim']\n",
    "\n",
    "reaction_times = dat_struct.rt1.tolist()[0]\n",
    "responses = [x[0] for x in dat_struct.perf1.tolist()]\n",
    "stimuli = [x[0] for x in dat_struct.conditions1.tolist()]\n",
    "\n",
    "subject = []\n",
    "\n",
    "for exp_run in list(zip(reaction_times, responses, stimuli)):\n",
    "    trial = dict.fromkeys(csv_keys)\n",
    "    trial['rt'], trial['response'], trial['stim'] = exp_run\n",
    "    subject.append(trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in a desirable format, we can dump it to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('../data/data_18333.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, csv_keys)\n",
    "    w.writeheader()\n",
    "    w.writerows(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all .mat files to .csv\n",
    "\n",
    "Convert data from .mat files to .csv files for use by the HDDM library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = ['rt', 'response', 'stim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mat2py(mat_path):\n",
    "    \"\"\"\n",
    "    Function to convert mat file to a pythonic data structure\n",
    "    Returns list of dictionaries mapping to spectific attributes\n",
    "    \"\"\"\n",
    "    data = scio.loadmat(mat_path, struct_as_record=False)\n",
    "    \n",
    "    dat_struct = data['data'][0,0]\n",
    "    \n",
    "    reaction_times = dat_struct.rt1.tolist()[0]\n",
    "    responses = [x[0] for x in dat_struct.perf1.tolist()]\n",
    "    stimuli = [x[0] for x in dat_struct.conditions1.tolist()]\n",
    "\n",
    "    subject = []\n",
    "\n",
    "    for exp_run in list(zip(reaction_times, responses, stimuli)):\n",
    "        trial = dict.fromkeys(keys)\n",
    "        trial['rt'], trial['response'], trial['stim'] = exp_run\n",
    "        subject.append(trial)\n",
    "    \n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subject2csv(subject, mat_path):\n",
    "    csv_path = mat_path.replace('.mat', '.csv')\n",
    "    print(csv_path)\n",
    "    with open(csv_path, 'w') as f:\n",
    "        w = csv.DictWriter(f, keys)\n",
    "        w.writeheader()\n",
    "        w.writerows(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/pilot_subjects/data_17991.csv\n",
      "../data/pilot_subjects/data_18288.csv\n",
      "../data/pilot_subjects/data_18325.csv\n",
      "../data/pilot_subjects/data_18333.csv\n",
      "../data/pilot_subjects/data_18334.csv\n",
      "../data/pilot_subjects/data_18350.csv\n",
      "../data/pilot_subjects/data_18547.csv\n",
      "../data/pilot_subjects/data_18619.csv\n",
      "../data/pilot_subjects/data_18864.csv\n",
      "../data/pilot_subjects/data_18919.csv\n",
      "../data/pilot_subjects/data_18977.csv\n",
      "../data/pilot_subjects/data_18978.csv\n",
      "../data/pilot_subjects/data_18979.csv\n",
      "../data/pilot_subjects/data_18988.csv\n",
      "../data/pilot_subjects/data_19686.csv\n",
      "../data/pilot_subjects/data_19687.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Iterate through all .mat files in the data directory and \n",
    "convert them to csv format\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "\n",
    "data_dir = '../data/pilot_subjects/'\n",
    "\n",
    "mat_files = glob.glob(str(data_dir) + '*.mat')\n",
    "\n",
    "for mat in mat_files:\n",
    "    subject2csv(mat2py(mat), mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cleaned-up version of the above is found under `utils/matparser.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
